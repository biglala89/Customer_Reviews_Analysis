{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn import decomposition\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'customer_review_analysis.db'\n",
    "\n",
    "query = \"\"\"select name, rating, comment, timestamp_\n",
    "            from reviews r \n",
    "            join users u \n",
    "            on r.id = u.id\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(os.path.join(os.getcwd(), db_file))\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Timestamp_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krystof</td>\n",
       "      <td>5</td>\n",
       "      <td>Great prices and customer service, shipping pr...</td>\n",
       "      <td>Friday, October 19, 2018 - 7:45:41 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JACK</td>\n",
       "      <td>5</td>\n",
       "      <td>easy to find parts</td>\n",
       "      <td>Friday, October 19, 2018 - 7:45:37 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent. The BEST in the business.</td>\n",
       "      <td>Friday, October 19, 2018 - 7:35:03 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jay</td>\n",
       "      <td>5</td>\n",
       "      <td>Just my latest order from B&amp;H always satisfied...</td>\n",
       "      <td>Friday, October 19, 2018 - 7:26:05 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chuck</td>\n",
       "      <td>5</td>\n",
       "      <td>Easy, quick and great website. Found everythin...</td>\n",
       "      <td>Friday, October 19, 2018 - 6:46:44 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Rating                                            Comment  \\\n",
       "0  Krystof       5  Great prices and customer service, shipping pr...   \n",
       "1     JACK       5                                 easy to find parts   \n",
       "2   George       5               Excellent. The BEST in the business.   \n",
       "3      jay       5  Just my latest order from B&H always satisfied...   \n",
       "4    Chuck       5  Easy, quick and great website. Found everythin...   \n",
       "\n",
       "                              Timestamp_  \n",
       "0  Friday, October 19, 2018 - 7:45:41 PM  \n",
       "1  Friday, October 19, 2018 - 7:45:37 PM  \n",
       "2  Friday, October 19, 2018 - 7:35:03 PM  \n",
       "3  Friday, October 19, 2018 - 7:26:05 PM  \n",
       "4  Friday, October 19, 2018 - 6:46:44 PM  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data from sqlite db\n",
    "df = pd.read_sql(query, connect_db(db_name))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('January', 2073),\n",
      "             ('February', 2040),\n",
      "             ('March', 1943),\n",
      "             ('April', 1797),\n",
      "             ('May', 2199),\n",
      "             ('June', 2140),\n",
      "             ('July', 2136),\n",
      "             ('August', 1960),\n",
      "             ('September', 908),\n",
      "             ('October', 920),\n",
      "             ('November', 0),\n",
      "             ('December', 0)])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Monthly number of reviews for year 2018 so far\n",
    "def monthly_count():\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    monthly_reviews = OrderedDict()\n",
    "    for month in months:\n",
    "        counts = df[df.Timestamp_.str.contains('.*?{}\\s+\\d+,\\s+2018.*?'.format(month), case=False)].shape[0]\n",
    "        monthly_reviews[month] = counts\n",
    "    return monthly_reviews\n",
    "\n",
    "ret = monthly_count()\n",
    "pprint (ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English Stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great prices and customer service, shipping prices are either free or priced fairly.',\n",
       " 'easy to find parts',\n",
       " 'Excellent. The BEST in the business.',\n",
       " 'Just my latest order from B&H always satisfied with products and service !',\n",
       " 'Easy, quick and great website. Found everything I needed fast.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listify comments from dataframe\n",
    "comments = df.Comment.tolist()\n",
    "comments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19880"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenization(text):\n",
    "    \"\"\"tokenize sentences and words; filter out tokens not containing letters\"\"\"\n",
    "    tokens = []\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word not in stopwords:\n",
    "                tokens.append(word)\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "def tokenization_and_stemming(text):\n",
    "    \"\"\"tokenize and stem sentences and words\"\"\"\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word not in stopwords]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_stemmed = []\n",
    "comments_tokenized = []\n",
    "\n",
    "for c in comments:\n",
    "    \n",
    "    token_stem_res = tokenization_and_stemming(c)\n",
    "    comments_stemmed.extend(token_stem_res)\n",
    "    \n",
    "    tokenized_res = tokenization(c)\n",
    "    comments_tokenized.extend(tokenized_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_token_mapper = {comments_stemmed[i]:comments_tokenized[i] for i in range(len(comments_stemmed))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6741"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stem_token_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 19880 comments and 7 terms.\n"
     ]
    }
   ],
   "source": [
    "#define vectorizer parameters\n",
    "tfidf_model = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(1,1))\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(comments) #fit the vectorizer to comments\n",
    "\n",
    "print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n",
    "      \" comments and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alway', 'b', 'easi', 'great', 'h', 'price', 'servic']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_selected_words = tfidf_model.get_feature_names()\n",
    "tf_selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         ... 0.28129143 0.68354226 0.18743241]\n",
      " [0.         1.         0.         ... 0.         0.60546603 0.74565859]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.28129143 0.         0.         ... 1.         0.54105068 0.66632819]\n",
      " [0.68354226 0.60546603 0.         ... 0.54105068 1.         0.81198827]\n",
      " [0.18743241 0.74565859 0.         ... 0.66632819 0.81198827 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_matrix = cosine_similarity(tfidf_matrix)\n",
    "print (cos_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
